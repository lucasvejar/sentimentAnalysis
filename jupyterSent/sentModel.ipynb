{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lv11/conda-env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import plac\n",
    "import random\n",
    "import pathlib\n",
    "import cytoolz\n",
    "import numpy as np\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "import thinc.extra.datasets\n",
    "from spacy.compat import pickle\n",
    "import spacy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------>   Loading spaCy   <------------\n"
     ]
    }
   ],
   "source": [
    "class SentimentAnalyser(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls,path,nlp,max_length):\n",
    "        return \"Some\"\n",
    "\n",
    "    def __init__(self, model, max_length=100):  \n",
    "        self._model = model\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        x = \"some\"\n",
    "        y = \"some\"\n",
    "\n",
    "\n",
    "def get_labelled_sentences(docs, doc_labels): \n",
    "    labels = []\n",
    "\n",
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    dev_texts,\n",
    "    dev_labels,\n",
    "    lstm_shape,\n",
    "    lstm_settings,\n",
    "    lstm_optimizer,\n",
    "    batch_size=100,\n",
    "    nb_epoch=5,\n",
    "    by_sentence=True\n",
    "):\n",
    "    print(\"------>   Loading spaCy   <------------\")\n",
    "    nlp = spacy.load('en_vectors_web_lg')\n",
    "    nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
    "    embeddings = get_embeddings(nlp.vocab)\n",
    "    model = compile_lstm(embeddings, lstm_shape, lstm_settings)\n",
    "\n",
    "\n",
    "\n",
    "def compile_lstm(embeddings, shape, settings):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            embeddings.shape[0],\n",
    "            embeddings.shape[1],\n",
    "            input_length=shape[\"max_length\"],\n",
    "            trainable=False,\n",
    "            weights=[embeddings],\n",
    "            mask_zero=True\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        TimeDistributed(Dense(shape[\"nr_hidden\"],use_bias=False))\n",
    "    )\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                shape['nr_hidden'],\n",
    "                recurrent_dropout = settings['dropout'],\n",
    "                dropout= settings['dropout']\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(shape['nr_class'],activation='sigmoid'),\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer= Adam(lr=settings['lr']),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_embeddings(vocab):\n",
    "    return vocab.vectors.data\n",
    "\n",
    "\n",
    "def evaluate(model_dir, texts, labels, max_length=100):\n",
    "    nlp = spacy.load(\"en_vectors_web_lg\")\n",
    "\n",
    "\n",
    "def read_data(data_dir, limit=0):\n",
    "    dataset = pd.read_csv(data_dir / 'tweet_sentiment.csv')\n",
    "    df = pd.DataFrame(data=dataset.values, columns=dataset.columns)\n",
    "    nf = pd.DataFrame(data=[tweet for tweet in df['text']], columns=['Tweets'])        \n",
    "    tweets = nf['Tweets']\n",
    "    sentiments = []\n",
    "    for sentiment in df['sentiment']:  \n",
    "        sentiments.append(-1 if sentiment=='negative' else (1 if sentiment=='positive' else 0))\n",
    "    \n",
    "    examples = zip(tweets,sentiments)\n",
    "    examples = list(examples)\n",
    "\n",
    "    if limit >= 1:\n",
    "        examples = examples[:limit]\n",
    "    return zip(*examples)  # Unzips into two lists\n",
    "\n",
    "\n",
    "def main(\n",
    "    model_dir='/home/lv11/Documents/ProyectosPython/sentimentAnalysis/model_lstm',\n",
    "    train_dir= pathlib.Path('/home/lv11/Documents/ProyectosPython/sentimentAnalysis/train'),\n",
    "    dev_dir= pathlib.Path('/home/lv11/Documents/ProyectosPython/sentimentAnalysis/test'),\n",
    "    is_runtime=False,\n",
    "    nr_hidden= 64,\n",
    "    max_length = 100,\n",
    "    dropout = 0.5,\n",
    "    learn_rate = 0.001,\n",
    "    nb_epoch = 5,\n",
    "    batch_size = 256,\n",
    "    nr_examples = -1\n",
    "):\n",
    "    # directory path\n",
    "    model_dir = pathlib.Path(model_dir)\n",
    "    # reading the data\n",
    "    dev_texts, dev_labels = read_data(dev_dir)\n",
    "    train_texts, train_labels = read_data(train_dir)\n",
    "    #converting labels as array\n",
    "    train_labels = np.asarray(train_labels, dtype=\"int32\")\n",
    "    dev_labels = np.asarray(dev_labels, dtype=\"int32\")\n",
    "\n",
    "    lstm = train(\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        dev_texts,\n",
    "        dev_labels,\n",
    "        {\"nr_hidden\": nr_hidden, \"max_length\": max_length, \"nr_class\": 1},\n",
    "        {\"dropout\": dropout, \"lr\": learn_rate},\n",
    "        {},\n",
    "        nb_epoch= nb_epoch,\n",
    "        batch_size = batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('conda-env': venv)",
   "language": "python",
   "name": "python36964bitcondaenvvenv7826cefca42d4575bfa69ede04b4b777"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
